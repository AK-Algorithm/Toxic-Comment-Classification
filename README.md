# Toxic Comment Classification

## Description
This project aims to classify online comments as either toxic or non-toxic using machine learning techniques.

## Table of Contents
- [Background](#background)
- [Dataset](#dataset)
- [Getting Started](#getting-started)
- [Results and Evaluation](#results-and-evaluation)
- [Features](#features)

## Background
Online platforms often face challenges with toxic comments that can harm user experience and community engagement. This project seeks to identify and classify comments into toxic and non-toxic categories using natural language processing (NLP) and machine learning.

## Dataset
The dataset provided used for this project is sourced from a univeristy assignment. 
- **Format**: CSV
- **Structure**: The dataset contains the following columns:
  - `id`: Unique identifier for each comment.
  - `comment_text`: The text of the comment.
  - `toxic`: Binary label indicating if the comment is toxic (1) or non-toxic (0).

## Getting Started
This project is primarily based on a Jupyter Notebook. After installation, you can open and run the notebook to classify the comments.

## Results and Evaluation
The detailed results and evaluation are available in the final report (PDF format)and in markdown format within the Jupyter Notebook.

## Features
The project includes the following key features:

- Classify comments into toxic and non-toxic categories.
- Exploratory data analysis (EDA) and data cleaning were performed to identify trends and patterns in the dataset.
- Use of NLP models for better accuracy.
- Customizable preprocessing pipeline for text cleaning and feature extraction.
- Evaluated model performance using metrics such as precision, recall, and F1 score.


